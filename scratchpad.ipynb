{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fetch card images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art_scan import process_query\n",
    "\n",
    "queries = [\n",
    "    \"Balefire Dragon\",\n",
    "]\n",
    "\n",
    "[process_query(q) for q in queries];"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Alter File MD5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import os\n",
    "\n",
    "\n",
    "def parse_file_path(path: str, file_separator: str = \"/\") -> Tuple[str, str, str]:\n",
    "    \"\"\"Parse a file path into the full directory, file name, and extension. \n",
    "\n",
    "    Args:\n",
    "        path (str): Full path to file\n",
    "        file_separator (str, optional): File separator to use. Defaults to \"\\\\\".\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str, str]: A tuple with three elements containing:\n",
    "            - Full directory path to the file\n",
    "            - Name of the file (without full directory path)\n",
    "            - Extension of the file\n",
    "    \"\"\"\n",
    "    path_tokens = path.split(file_separator)\n",
    "    file_name = path_tokens[-1]\n",
    "    file_path = file_separator.join(path_tokens[:-1])\n",
    "    \n",
    "    ext_tokens = file_name.split('.')\n",
    "    file_name = ext_tokens[0] if len(ext_tokens) <= 1 else '.'.join(ext_tokens[:-1])\n",
    "    file_ext = ext_tokens[-1]\n",
    "\n",
    "    return (file_path, file_name, file_ext)\n",
    "\n",
    "\n",
    "def duplicate_file(source_path: str, destination_path: str, count: int):\n",
    "    file_contents = None\n",
    "    with open(source_path, 'rb') as orig_file:\n",
    "        file_contents = orig_file.read()\n",
    "\n",
    "    _, file_name, file_ext = parse_file_path(source_path)\n",
    "    for i in range(count):\n",
    "        alt_file_path = os.path.join(destination_path, f\"{file_name} [{i + 1}].{file_ext}\")\n",
    "        with open(alt_file_path, 'wb') as alt_file:\n",
    "            alt_file.write(file_contents + (i * b'\\0'))\n",
    "\n",
    "# image_path = \"C:\\\\Users\\\\evanh\\\\My Drive\\\\MTG\\\\Proxies\\\\mpc-ready\\\\Artifact\\\\Aetherflux Reservoir (Extended).png\"\n",
    "# destination_path = \"C:\\\\Users\\\\evanh\\\\My Drive\\\\MTG\\\\Proxies\\\\temp\"\n",
    "# duplicate_file(image_path, destination_path, 2)\n",
    "\n",
    "# CHECK\n",
    "# hashlib.md5(open(image_path, 'rb').read()).hexdigest()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Pull Private Proxy List from Google Sheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import namedtuple\n",
    "# from googleapiclient import discovery\n",
    "# from lib.google_auth import get_creds\n",
    "\n",
    "# INV_SHEETS_ID = '13ofTLZFmPMkT09Np2US8KF_JmTfgqdeQ5aeY16L43s0'\n",
    "# INV_RANGE = 'Inventory!A:L'\n",
    "\n",
    "# service = discovery.build('sheets', 'v4', credentials=get_creds())\n",
    "\n",
    "# # Call the Sheets API\n",
    "# sheets_args = dict(\n",
    "#     spreadsheetId=INV_SHEETS_ID,\n",
    "#     range=INV_RANGE,\n",
    "# )\n",
    "# result = service.spreadsheets().values().get(**sheets_args).execute()\n",
    "# proxy_list = list(result.get('values', []))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Pull Public Proxy List from Google Sheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "sheet_id = '13ofTLZFmPMkT09Np2US8KF_JmTfgqdeQ5aeY16L43s0'\n",
    "url = f'https://docs.google.com/spreadsheet/ccc?key={sheet_id}&output=csv'\n",
    "\n",
    "# sheet_id = \"1QRqqMGxbZWZYaa9UXeE3PwrQxZjRh7i_3TNTzqwlN5Y\"\n",
    "# sheet_name = \"Inventory\"\n",
    "# url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    download = s.get(url)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    proxy_list = list(csv.reader(decoded_content.splitlines(), delimiter=','))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Load List in Python Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "# from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class Proxy:\n",
    "    \"\"\"Class to store relevant proxy information.\"\"\"\n",
    "    name: str\n",
    "    type: str\n",
    "    # last_edited: datetime\n",
    "    order_count: int\n",
    "\n",
    "    COL_MAP = {\n",
    "        \"name\": 0,\n",
    "        \"type\": 1,\n",
    "        # \"last_edited\": 2,\n",
    "        \"order_count\": 11,\n",
    "    }\n",
    "    DATE_FORMAT_STR = \"%b %d %H:%M\"\n",
    "    \n",
    "    @property\n",
    "    def is_mdfc(self) -> bool:\n",
    "        return '//' in self.name\n",
    "\n",
    "    @classmethod\n",
    "    def from_row(cls, row):\n",
    "        return cls(\n",
    "            name=row[cls.COL_MAP['name']],\n",
    "            type=row[cls.COL_MAP['type']],\n",
    "            # last_edited=datetime.strptime(row[cls.COL_MAP['last_edited']], cls.DATE_FORMAT_STR),\n",
    "            order_count=int(row[cls.COL_MAP['order_count']])\n",
    "        )\n",
    "\n",
    "# Load non-empty rows into `Proxy` type\n",
    "all_proxies = [Proxy.from_row(p) for p in proxy_list[4:] if len(p[0]) > 0]\n",
    "proxies_to_print = [p for p in all_proxies if p.order_count > 0]\n",
    "len(proxies_to_print)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Find missing proxy files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROXY_DIR = \"C:/Users/evanh/My Drive/MTG/Proxies/mpc-ready\"\n",
    "\n",
    "card_types = list(set([p.type for p in proxies_to_print]))\n",
    "proxies_by_type = {\n",
    "    type_: [p for p in proxies_to_print if p.type == type_]\n",
    "    for type_ in card_types\n",
    "}\n",
    "\n",
    "for card_type in card_types:\n",
    "    files = os.listdir(f\"{PROXY_DIR}/{card_type}\")\n",
    "    for proxy in proxies_by_type[card_type]:\n",
    "        found = False\n",
    "        for file in files:\n",
    "            if proxy.name in file:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(proxy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Write out files for order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_SIZE = 55\n",
    "FOLDER_NAME = \"proxies_{number:02d}\"\n",
    "TEMP_FOLDER = \"C:/Users/evanh/Temp/landing\"\n",
    "OUTPUT_FOLDER = \"C:/Users/evanh/Temp/mpc\"\n",
    "PROXY_DIR = \"C:/Users/evanh/My Drive/MTG/Proxies/mpc-ready\"\n",
    "\n",
    "# Write all files out to landing zone\n",
    "for proxy in proxies_to_print:\n",
    "    search_path = f\"{PROXY_DIR}/{proxy.type}\"\n",
    "    file_names = [f for f in os.listdir(search_path) if f.startswith(f\"{proxy.name}.\")]\n",
    "\n",
    "    if len(file_names) < 1:\n",
    "        print(f\"Unable to find [{proxy.name}] at [{search_path}]\")\n",
    "        continue\n",
    "    elif len(file_names) > 1:\n",
    "        print(f\"Found multiple matches for {proxy.name} at [{search_path}]\")\n",
    "        print(file_names)\n",
    "        continue\n",
    "\n",
    "    proxy_path = f\"{PROXY_DIR}/{proxy.type}/{file_names[0]}\"\n",
    "    duplicate_file(proxy_path, TEMP_FOLDER, proxy.order_count)\n",
    "\n",
    "# Move files into subfolders of fixed size (`FOLDER_SIZE`)\n",
    "current_folder = 0\n",
    "while len(os.listdir(TEMP_FOLDER)) > 0:\n",
    "    # Create temp folder\n",
    "    output_folder = os.path.join(OUTPUT_FOLDER, FOLDER_NAME.format(number=current_folder))\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "    # Move a number of files up to the configured folder size\n",
    "    for file in os.listdir(TEMP_FOLDER)[:FOLDER_SIZE]:\n",
    "        source_file = os.path.join(TEMP_FOLDER, file)\n",
    "        output_file = os.path.join(output_folder, file)\n",
    "        os.rename(source_file, output_file)\n",
    "\n",
    "    current_folder += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Handle MDFCs separately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfc_proxies = [p for p in proxies_to_print if p.is_mdfc]\n",
    "for proxy in mdfc_proxies:\n",
    "    for name in proxy.name.split(' // '):\n",
    "        search_path = f\"{PROXY_DIR}/{proxy.type}\"\n",
    "        file_names = [f for f in os.listdir(search_path) if f.startswith(f\"{name}.\")]\n",
    "\n",
    "        if len(file_names) < 1:\n",
    "            print(f\"Unable to find [{name}] at [{search_path}]\")\n",
    "            continue\n",
    "        elif len(file_names) > 1:\n",
    "            print(f\"Found multiple matches for {name} at [{search_path}]\")\n",
    "            print(file_names)\n",
    "            continue\n",
    "\n",
    "        proxy_path = f\"{PROXY_DIR}/{proxy.type}/{file_names[0]}\"\n",
    "        duplicate_file(proxy_path, TEMP_FOLDER, proxy.order_count)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15c7ff3fcc4aa4047bf6eca4e66b55cd0ecda7020ad54c7fc1b31e83da224f91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
